{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59002bdb-ade2-467f-8976-ef40c846c8fa",
   "metadata": {},
   "source": [
    "This notebook will take TropOMI netCDF files and aggregate them to Colorado tract and County boundaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b421c6-bb19-4280-b36f-25cfcfeedba6",
   "metadata": {},
   "source": [
    "STEP 1 - convert netCDF to geotiff\n",
    "In this first step you will create a geotiff from your netCDF.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4636a7f-c913-4887-9470-1fcdc0d086f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/xarray/backends/plugins.py:117: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/xarray/backends/plugins.py:117: RuntimeWarning: 'scipy' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/xarray/backends/plugins.py:126: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/xarray/backends/plugins.py:126: RuntimeWarning: 'h5netcdf' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/xarray/backends/plugins.py:126: RuntimeWarning: 'scipy' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'rasterio', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttp://xarray.pydata.org/en/stable/getting-started-guide/installing.html\nhttp://xarray.pydata.org/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/glade/derecho/scratch/boehnert/tmp/ipykernel_13047/1227623281.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Open dataset using xarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetcdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# --- Inspect available variables ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, backend_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguess_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/xarray/backends/plugins.py\u001b[0m in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'rasterio', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttp://xarray.pydata.org/en/stable/getting-started-guide/installing.html\nhttp://xarray.pydata.org/en/stable/user-guide/io.html"
     ]
    }
   ],
   "source": [
    "# this works for TropOmi\n",
    "# convert netCDF to geotiff\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# --- Load NetCDF file ---\n",
    "#\n",
    "# Change this based on where your netCDF is stored\n",
    "#\n",
    "netcdf_path = r\"/glade/derecho/scratch/boehnert/AQE/tropOmi/2027 Presidential AI Challenge\"\n",
    "#\n",
    "# --- Save as GeoTIFF ---\n",
    "# change this to where you want your geotiff to be stored\n",
    "#\n",
    "tif_path = r\"/glade/derecho/scratch/boehnert/AQE/rasters/tropomi_n02_2022.tif\"\n",
    "\n",
    "# Open dataset using xarray\n",
    "ds = xr.open_dataset(netcdf_path)\n",
    "\n",
    "# --- Inspect available variables ---\n",
    "print(ds.data_vars)\n",
    "\n",
    "# Choose your variable — adjust if needed\n",
    "var_name = \"Tropospheric_NO2\"  # or use print(ds.data_vars) to confirm\n",
    "\n",
    "# Read variable and coordinates\n",
    "no2 = ds[var_name][:, :]\n",
    "lat = ds[\"Latitude\"][:]\n",
    "lon = ds[\"Longitude\"][:]\n",
    "\n",
    "\n",
    "# Make sure dimensions match\n",
    "print(\"NO2 shape:\", no2.shape)\n",
    "print(\"Lat size:\", len(lat))\n",
    "print(\"Lon size:\", len(lon))\n",
    "\n",
    "# --- Flip data vertically to match GeoTIFF convention ---\n",
    "no2_flipped = np.flipud(no2.values)\n",
    "lat_flipped = lat[::-1]  # To match flipped data\n",
    "\n",
    "# --- Define transform (top-left corner = NW) ---\n",
    "res_lon = np.abs(lon[1] - lon[0])\n",
    "res_lat = np.abs(lat[1] - lat[0])\n",
    "\n",
    "transform = from_origin(\n",
    "    west=lon.min() - res_lon / 2,\n",
    "    north=lat.max() + res_lat / 2,  # Because we flipped lat\n",
    "    xsize=res_lon,\n",
    "    ysize=res_lat,\n",
    ")\n",
    "\n",
    "\n",
    "# --- Handle fill values ---\n",
    "no2_masked = np.ma.masked_invalid(no2_flipped)\n",
    "nodata_val = -9999\n",
    "\n",
    "# --- Save as GeoTIFF ---\n",
    "\n",
    "raster_meta = {\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"height\": no2_masked.shape[0],\n",
    "    \"width\": no2_masked.shape[1],\n",
    "    \"count\": 1,\n",
    "    \"dtype\": \"float32\",\n",
    "    \"crs\": \"EPSG:4326\",\n",
    "    \"transform\": transform,\n",
    "    \"nodata\": nodata_val,\n",
    "}\n",
    "\n",
    "with rasterio.open(tif_path, \"w\", **raster_meta) as dst:\n",
    "    dst.write(no2_masked.filled(nodata_val).astype(\"float32\"), 1)\n",
    "\n",
    "print(f\"✅ Corrected GeoTIFF saved: {tif_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96c910c-50b3-421f-8110-54204e33f157",
   "metadata": {},
   "source": [
    "STEP 2 - Zonal Statistics\n",
    "In this step you will perform a zonal statistics and output .csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9285ed-df77-41c4-90f2-aa15804ee231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up for zonal stats\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from exactextract import exact_extract\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "# CHANGE this to point to your shapefiles\n",
    "shapeTract = r\"/glade/derecho/scratch/boehnert/AQE/shapefile/Colorado_tracts.shp\"\n",
    "shapeCounty = r\"/glade/derecho/scratch/boehnert/AQE/shapefile/Colorado_Counties.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3134dc-5a58-43a0-90f5-f2252f77c80c",
   "metadata": {},
   "source": [
    "Zonal Stats for Colorado Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff72583-8623-4c2d-b9c7-c56be514dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO2\n",
    "# zonal stats to tracts\n",
    "\n",
    "# Load shapefile and match CRS\n",
    "tracts = gpd.read_file(shapeTract)\n",
    "# CHANGE this to point to your geotiff you created in Step 1\n",
    "#\n",
    "rast = r\"/glade/derecho/scratch/boehnert/AQE/rasters/tropomi_n02_2022.tif\"\n",
    "# Output CSV\n",
    "# Change this to be where you want to store the CSV\n",
    "#\n",
    "out = r\"/glade/derecho/scratch/boehnert/AQE/output/tropOmi_tract_no2_2022.csv\"\n",
    "\n",
    "\n",
    "# Open NO₂ raster\n",
    "with rasterio.open(rast) as src:\n",
    "    # Extract weighted means (GeoJSON-style input)\n",
    "    # means = [exact_extract(src, mapping(geom), ['mean'])[0]['mean'] for geom in tracts.geometry]\n",
    "    means = exact_extract(rast, tracts, [\"mean\"], output=\"pandas\")\n",
    "    medians = exact_extract(rast, tracts, [\"median\"], output=\"pandas\")\n",
    "    std = exact_extract(rast, tracts, [\"stdev\"], output=\"pandas\")\n",
    "    count = exact_extract(rast, tracts, [\"count\"], output=\"pandas\")\n",
    "\n",
    "# Check length\n",
    "print(len(means))  # Should be 1447\n",
    "\n",
    "# Assign and export\n",
    "tracts[\"MEAN\"] = means\n",
    "tracts[\"MEDIAN\"] = medians\n",
    "tracts[\"STD\"] = std\n",
    "tracts[\"COUNT\"] = count\n",
    "\n",
    "\n",
    "# Export desired fields\n",
    "tracts[[\"FIPS\", \"SQKM\", \"COUNT\", \"MEAN\", \"MEDIAN\", \"STD\"]].to_csv(out, index=False)\n",
    "print(f\"✅ CSV file created: {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c07215-e904-4c26-bc35-096205506e0c",
   "metadata": {},
   "source": [
    "Zonal Stats for County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b95993-c24d-4ea7-88c7-296192850150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO2\n",
    "# zonal stats to counties\n",
    "\n",
    "# Load shapefile and match CRS\n",
    "county = gpd.read_file(shapeCounty)\n",
    "# CHANGE this to point to your geotiff you created in Step 1\n",
    "#\n",
    "rast = r\"/glade/derecho/scratch/boehnert/AQE/rasters/tropomi_n02_2022.tif\"\n",
    "# Output CSV\n",
    "# Change to be where you are storing the CSV\n",
    "#\n",
    "out = r\"/glade/derecho/scratch/boehnert/AQE/output/tropOmi_tract_no2_2022.csv\"\n",
    "\n",
    "\n",
    "# Open NO₂ raster\n",
    "with rasterio.open(rast) as src:\n",
    "    # Extract weighted means (GeoJSON-style input)\n",
    "    # means = [exact_extract(src, mapping(geom), ['mean'])[0]['mean'] for geom in tracts.geometry]\n",
    "    means = exact_extract(rast, county, [\"mean\"], output=\"pandas\")\n",
    "    medians = exact_extract(rast, county, [\"median\"], output=\"pandas\")\n",
    "    std = exact_extract(rast, county, [\"stdev\"], output=\"pandas\")\n",
    "    count = exact_extract(rast, county, [\"count\"], output=\"pandas\")\n",
    "\n",
    "# Check length\n",
    "print(len(means))  # Should be 1447\n",
    "\n",
    "# Assign and export\n",
    "county[\"MEAN\"] = means\n",
    "county[\"MEDIAN\"] = medians\n",
    "county[\"STD\"] = std\n",
    "county[\"COUNT\"] = count\n",
    "\n",
    "\n",
    "# Export desired fields\n",
    "county[[\"FIPS\", \"SQKM\", \"COUNT\", \"MEAN\", \"MEDIAN\", \"STD\"]].to_csv(out, index=False)\n",
    "print(f\"✅ CSV file created: {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7db7a2-7745-43a4-bc33-2c0f451ac581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a7349-7fea-49ce-8fcb-368daa90df68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3570c-243e-444a-a044-9391a2e5b9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis]",
   "language": "python",
   "name": "conda-env-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
