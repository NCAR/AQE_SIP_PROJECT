{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59002bdb-ade2-467f-8976-ef40c846c8fa",
   "metadata": {},
   "source": [
    "This script will take the SIP model output and aggregate it to the county and tract boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072b453-e116-45f0-a4e2-9877c64a5f14",
   "metadata": {},
   "source": [
    "***the SIP output does not conform to CF conventions.  So you need to add the Lat and lon variables as dimensions to the tracer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999809a5-7b38-4452-8be7-c148e606195c",
   "metadata": {},
   "source": [
    "STEP 1 - add latitude and longitude as dimensions to SIP output \n",
    "\n",
    "**this will add lat and lon as dimensions instead of row and col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eeec936-0641-49f5-94b2-ac6f5ad4a89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote /glade/derecho/scratch/boehnert/AQE/SIP/sept_camxv72_sip_pm25_avg.nc after regridding PM25 to regular (latitude, longitude).\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.interpolate import griddata  # used only when lat/lon are 2-D\n",
    "\n",
    "#\n",
    "#CHANGE this based on the SIP netcdf you want to work with\n",
    "#\n",
    "nc_in = r\"/glade/derecho/scratch/lacey/ForJenn/camxv72_cb6r5_2016_PM25_avg.nc\"  \n",
    "nc_out = r\"/glade/derecho/scratch/boehnert/AQE/SIP/sept_camxv72_sip_pm25_avg.nc\"\n",
    "\n",
    "\n",
    "# --- CONFIG ---\n",
    "#CHANGE the variable of interest\n",
    "varname = \"PM25\"          # your data variable\n",
    "latname = \"latitude\"      # variable containing latitude values\n",
    "lonname = \"longitude\"     # variable containing longitude values\n",
    "\n",
    "# Open\n",
    "ds = xr.open_dataset(nc_in)\n",
    "\n",
    "if varname not in ds:\n",
    "    raise ValueError(f\"{varname} not found in {nc_in}\")\n",
    "\n",
    "if latname not in ds or lonname not in ds:\n",
    "    raise ValueError(f\"Expected variables {latname} and {lonname} in {nc_in}\")\n",
    "\n",
    "da = ds[varname]\n",
    "latv = ds[latname]\n",
    "lonv = ds[lonname]\n",
    "\n",
    "# Identify the row/col dims used by FPRM (assume the last two are horizontal)\n",
    "if da.ndim < 2:\n",
    "    raise ValueError(f\"{varname} must be at least 2D (row, col). Got {da.dims}\")\n",
    "\n",
    "row_dim, col_dim = da.dims[-2], da.dims[-1]\n",
    "\n",
    "def write_out(dataset, path):\n",
    "    # Light compression and keep float32\n",
    "    encoding = {v: {\"zlib\": True, \"complevel\": 4} for v in dataset.data_vars}\n",
    "    # Preserve dtype for the main var\n",
    "    encoding[varname] = {**encoding.get(varname, {}), \"dtype\": \"float32\", \"_FillValue\": np.float32(np.nan)}\n",
    "    dataset.to_netcdf(path, encoding=encoding)\n",
    "\n",
    "# ---------- CASE A: 1-D lat/lon (easy swap) ----------\n",
    "if latv.ndim == 1 and lonv.ndim == 1 and latv.dims[0] == row_dim and lonv.dims[0] == col_dim:\n",
    "    # Attach 1D coords and swap dims\n",
    "    out = ds.assign_coords({\n",
    "        \"latitude\": (row_dim, latv.values.astype(np.float32)),\n",
    "        \"longitude\": (col_dim, lonv.values.astype(np.float32)),\n",
    "    }).swap_dims({row_dim: \"latitude\", col_dim: \"longitude\"})\n",
    "\n",
    "    # Make sure the main var uses float32\n",
    "    out[varname] = out[varname].astype(\"float32\")\n",
    "\n",
    "    # CF-ish attrs\n",
    "    out[\"latitude\"].attrs.update(dict(standard_name=\"latitude\", units=\"degrees_north\"))\n",
    "    out[\"longitude\"].attrs.update(dict(standard_name=\"longitude\", units=\"degrees_east\"))\n",
    "\n",
    "    write_out(out, nc_out)\n",
    "    print(f\"Wrote {nc_out} with {varname}(latitude, longitude).\")\n",
    "\n",
    "# ---------- CASE B: 2-D lat/lon (curvilinear → regrid) ----------\n",
    "elif latv.ndim == 2 and lonv.ndim == 2 and latv.dims == (row_dim, col_dim) and lonv.dims == (row_dim, col_dim):\n",
    "\n",
    "    # Build a regular 1-D lat/lon grid based on median spacing\n",
    "    lat2d = np.asarray(latv.values, dtype=np.float64)\n",
    "    lon2d = np.asarray(lonv.values, dtype=np.float64)\n",
    "\n",
    "    # Estimate grid spacing (robust to NaNs)\n",
    "    def med_step(a, axis):\n",
    "        d = np.nanmedian(np.abs(np.diff(a, axis=axis)))\n",
    "        return float(d) if np.isfinite(d) and d > 0 else None\n",
    "\n",
    "    dlat = med_step(lat2d, axis=0) or med_step(lat2d, axis=1) or 0.01\n",
    "    dlon = med_step(lon2d, axis=1) or med_step(lon2d, axis=0) or 0.01\n",
    "\n",
    "    lat_min, lat_max = np.nanmin(lat2d), np.nanmax(lat2d)\n",
    "    lon_min, lon_max = np.nanmin(lon2d), np.nanmax(lon2d)\n",
    "\n",
    "    lat_new = np.arange(lat_min, lat_max + dlat * 0.5, dlat, dtype=np.float32)\n",
    "    lon_new = np.arange(lon_min, lon_max + dlon * 0.5, dlon, dtype=np.float32)\n",
    "    Lon_new, Lat_new = np.meshgrid(lon_new, lat_new)\n",
    "\n",
    "    # Prepare input points for interpolation\n",
    "    pts = np.column_stack((lon2d.ravel(), lat2d.ravel()))\n",
    "\n",
    "    # Move all non-horizontal dims to a single leading axis for looping\n",
    "    other_dims = da.dims[:-2]\n",
    "    other_sizes = [da.sizes[d] for d in other_dims]\n",
    "    flat_count = int(np.prod(other_sizes)) if other_sizes else 1\n",
    "\n",
    "    data = np.asarray(da.values, dtype=np.float32)\n",
    "    data = data.reshape((flat_count, data.shape[-2], data.shape[-1]))\n",
    "\n",
    "    out_stack = np.full((flat_count, lat_new.size, lon_new.size), np.nan, dtype=np.float32)\n",
    "\n",
    "    for i in range(flat_count):\n",
    "        vals = data[i].ravel()\n",
    "        mask = np.isfinite(vals)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        # 'nearest' is safest for coverage; change to 'linear' if desired\n",
    "        interp = griddata(pts[mask], vals[mask],\n",
    "                          (Lon_new, Lat_new),\n",
    "                          method=\"nearest\", fill_value=np.nan)\n",
    "        out_stack[i, :, :] = interp.astype(np.float32)\n",
    "\n",
    "    # Reshape back and build DataArray\n",
    "    if other_dims:\n",
    "        out_data = out_stack.reshape(*other_sizes, lat_new.size, lon_new.size)\n",
    "        out_dims = [*other_dims, \"latitude\", \"longitude\"]\n",
    "        coords = {d: ds.coords[d] if d in ds.coords else np.arange(ds.sizes[d]) for d in other_dims}\n",
    "    else:\n",
    "        out_data = out_stack[0]\n",
    "        out_dims = [\"latitude\", \"longitude\"]\n",
    "        coords = {}\n",
    "\n",
    "    coords.update({\n",
    "        \"latitude\": (\"latitude\", lat_new, {\"standard_name\":\"latitude\",\"units\":\"degrees_north\"}),\n",
    "        \"longitude\": (\"longitude\", lon_new, {\"standard_name\":\"longitude\",\"units\":\"degrees_east\"}),\n",
    "    })\n",
    "\n",
    "    out_da = xr.DataArray(out_data, dims=out_dims, coords=coords, name=varname, attrs=da.attrs)\n",
    "    out = xr.Dataset({varname: out_da})\n",
    "\n",
    "    write_out(out, nc_out)\n",
    "    print(f\"Wrote {nc_out} after regridding {varname} to regular (latitude, longitude).\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Unsupported shapes:\\n\"\n",
    "        f\"  {varname} dims: {da.dims}\\n\"\n",
    "        f\"  {latname} dims: {latv.dims}\\n\"\n",
    "        f\"  {lonname} dims: {lonv.dims}\\n\"\n",
    "        \"Expect 1-D lat(row) & lon(col), or 2-D lat(row,col) & lon(row,col).\"\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8104fbe2-5cb9-4b69-be8d-94365278b336",
   "metadata": {},
   "source": [
    "STEP 2 - Convert the netCDF to a Geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4636a7f-c913-4887-9470-1fcdc0d086f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    PM25     (TSTEP, LAY, latitude, longitude) float32 ...\n",
      "NO2 shape: (142, 183)\n",
      "Lat size: 142\n",
      "Lon size: 183\n",
      "NO2 masked shape: (142, 183)\n",
      "hello\n",
      "✅ Corrected GeoTIFF saved: /glade/derecho/scratch/boehnert/AQE/rasters/sept_sip_pm25_2016.tif\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "import numpy as np\n",
    "\n",
    "#CHANGE this based on the netCDF file you want to work with\n",
    "#\n",
    "# --- Load NetCDF file ---\n",
    "netcdf_path = r\"/glade/derecho/scratch/boehnert/AQE/SIP/sept_camxv72_sip_pm25_avg.nc\"\n",
    "# --- Save as GeoTIFF ---\n",
    "tif_path = r\"/glade/derecho/scratch/boehnert/AQE/rasters/sept_sip_pm25_2016.tif\"\n",
    "\n",
    "# Open dataset using xarray\n",
    "ds = xr.open_dataset(netcdf_path)\n",
    "\n",
    "# --- Inspect available variables ---\n",
    "print(ds.data_vars)\n",
    "\n",
    "# Choose your variable — adjust if needed\n",
    "var_name = \"PM25\"  # or use print(ds.data_vars) to confirm\n",
    "\n",
    "# Read variable and coordinates\n",
    "no2 = ds[var_name][0,0,:,:]\n",
    "lat = ds['latitude'][:]\n",
    "lon = ds['longitude'][:]\n",
    "\n",
    "\n",
    "# Make sure dimensions match\n",
    "print(\"NO2 shape:\", no2.shape)\n",
    "print(\"Lat size:\", len(lat))\n",
    "print(\"Lon size:\", len(lon))\n",
    "\n",
    "# --- Flip data vertically to match GeoTIFF convention ---\n",
    "no2_flipped = np.flipud(no2.values)\n",
    "lat_flipped = lat[::-1]  # To match flipped data\n",
    "\n",
    "# --- Define transform (top-left corner = NW) ---\n",
    "res_lon = np.abs(lon[1] - lon[0])\n",
    "res_lat = np.abs(lat[1] - lat[0])\n",
    "\n",
    "transform = from_origin(\n",
    "    west=lon.min() - res_lon / 2,\n",
    "    north=lat.max() + res_lat / 2,  # Because we flipped lat\n",
    "    xsize=res_lon,\n",
    "    ysize=res_lat\n",
    ")\n",
    "\n",
    "\n",
    "# --- Handle fill values ---\n",
    "no2_masked = np.ma.masked_invalid(no2_flipped)\n",
    "nodata_val = -9999\n",
    "\n",
    "# --- Save as GeoTIFF ---\n",
    "\n",
    "print(\"NO2 masked shape:\", no2_masked.shape)\n",
    "raster_meta = {\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"height\": no2_masked.shape[0],\n",
    "    \"width\": no2_masked.shape[1],\n",
    "    \"dtype\": \"float32\",\n",
    "    \"count\" : 1,\n",
    "    \"crs\": \"EPSG:4326\",\n",
    "    \"transform\": transform,\n",
    "    \"nodata\": nodata_val\n",
    "}\n",
    "\n",
    "with rasterio.open(tif_path, \"w\", **raster_meta) as dst:\n",
    "    print(\"hello\")\n",
    "    dst.write(no2_masked.filled(nodata_val).astype(\"float32\"),1)\n",
    "   \n",
    "\n",
    "print(f\"✅ Corrected GeoTIFF saved: {tif_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfc4ef4-cf58-4971-8238-7667a5e85d4f",
   "metadata": {},
   "source": [
    "STEP 3 - Perform Zonal statistics to aggregate the SIP model to county and tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76c81bb-db00-48de-9197-45cc5c696c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up for zonal stats\n",
    "import geopandas as gpd\n",
    "from exactextract import exact_extract\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "#CHANGE this to point to your shapefiles\n",
    "shapeTract = r\"/glade/derecho/scratch/boehnert/AQE/shapefile/Colorado_tracts.shp\"\n",
    "shapeCounty = r\"/glade/derecho/scratch/boehnert/AQE/shapefile/Colorado_Counties.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b9285ed-df77-41c4-90f2-aa15804ee231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1447\n"
     ]
    }
   ],
   "source": [
    "#PM 2.5\n",
    "#TRACTS aggregation\n",
    "\n",
    "# Load shapefile and match CRS\n",
    "tracts = gpd.read_file(shapeTract)\n",
    "# CHANGE this to point to your geotiff you created in Step 2\n",
    "#\n",
    "rast = r\"/glade/derecho/scratch/boehnert/AQE/rasters/sept_sip_pm25_2016.tif\"\n",
    "#Output CSV\n",
    "#\n",
    "out = r\"/glade/derecho/scratch/boehnert/AQE/output/sept_sip_tract_pm25_2016.csv\"\n",
    "\n",
    "\n",
    "# Open NO₂ raster\n",
    "with rasterio.open(rast) as src:\n",
    "    # Extract weighted means (GeoJSON-style input)\n",
    "    #means = [exact_extract(src, mapping(geom), ['mean'])[0]['mean'] for geom in tracts.geometry]\n",
    "    means = exact_extract(rast, tracts, [\"mean\"], output='pandas')\n",
    "    medians = exact_extract(rast, tracts, [\"median\"], output='pandas')\n",
    "    std = exact_extract(rast, tracts, [\"stdev\"], output='pandas')\n",
    "    count = exact_extract(rast, tracts, [\"count\"], output='pandas')\n",
    "    \n",
    "# Check length\n",
    "print(len(means))  # Should be 1447\n",
    "\n",
    "\n",
    "# Assign and export\n",
    "tracts['MEAN'] = means\n",
    "tracts['MEDIAN'] = medians\n",
    "tracts['STD'] = std\n",
    "tracts[\"COUNT\"] = count\n",
    "\n",
    "\n",
    "# Export desired fields\n",
    "tracts[['FIPS', 'SQKM', 'COUNT', 'MEAN', 'MEDIAN', 'STD']].to_csv(out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff72583-8623-4c2d-b9c7-c56be514dfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "#PM 2.5\n",
    "#COUNTIES Aggregation\n",
    "\n",
    "# Load shapefile and match CRS\n",
    "tracts = gpd.read_file(shapeCounty)\n",
    "#CHANGE this to point to your geotiff you created in Step 2\n",
    "#\n",
    "rast = r\"/glade/derecho/scratch/boehnert/AQE/rasters/sip_pm25_2016.tif\"\n",
    "#output CSV\n",
    "#\n",
    "out = r\"/glade/derecho/scratch/boehnert/AQE/output/sip_country_pm25_2016.csv\"\n",
    "\n",
    "# Open NO₂ raster\n",
    "with rasterio.open(rast) as src:\n",
    "    # Extract weighted means (GeoJSON-style input)\n",
    "    #means = [exact_extract(src, mapping(geom), ['mean'])[0]['mean'] for geom in tracts.geometry]\n",
    "    means = exact_extract(rast, tracts, [\"mean\"], output='pandas')\n",
    "    medians = exact_extract(rast, tracts, [\"median\"], output='pandas')\n",
    "    std = exact_extract(rast, tracts, [\"stdev\"], output='pandas')\n",
    "    count = exact_extract(rast, tracts, [\"count\"], output='pandas')\n",
    "    \n",
    "# Check length\n",
    "print(len(means))  # Should be 1447\n",
    "\n",
    "    \n",
    "# Assign and export\n",
    "tracts['MEAN'] = means\n",
    "tracts['MEDIAN'] = medians\n",
    "tracts['STD'] = std\n",
    "tracts[\"COUNT\"] = count\n",
    "\n",
    "\n",
    "# Export desired fields\n",
    "tracts[['FIPS', 'SQKM', 'COUNT', 'MEAN', 'MEDIAN', 'STD']].to_csv(out, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b7db7a2-7745-43a4-bc33-2c0f451ac581",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Unhandled feature datatype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38226/967623917.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrast\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Compute weighted mean NO2 per tract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexact_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"/glade/derecho/scratch/boehnert/AQE/output/weighted_NO2_by_tract_2019_exact2.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_38226/967623917.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrast\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Compute weighted mean NO2 per tract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexact_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"/glade/derecho/scratch/boehnert/AQE/output/weighted_NO2_by_tract_2019_exact2.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/exactextract/exact_extract.py\u001b[0m in \u001b[0;36mexact_extract\u001b[0;34m(rast, vec, ops, weights, include_cols, include_geom, strategy, max_cells_in_memory, grid_compat_tol, output, output_options, progress)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mrast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_raster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_raster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_options\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/exactextract/exact_extract.py\u001b[0m in \u001b[0;36mprep_vec\u001b[0;34m(vec)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unhandled feature datatype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Unhandled feature datatype"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e03a7349-7fea-49ce-8fcb-368daa90df68",
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "Failed to read GeoJSON data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: Failed to read GeoJSON data",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38226/2252455037.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load tract geometries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtracts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# or .shp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Open NO₂ raster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0m\u001b[1;32m    257\u001b[0m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/boehnert/conda-envs/analysis/lib/python3.9/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: Failed to read GeoJSON data"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3570c-243e-444a-a044-9391a2e5b9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis]",
   "language": "python",
   "name": "conda-env-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
